{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12366770,"sourceType":"datasetVersion","datasetId":7797216},{"sourceId":12367364,"sourceType":"datasetVersion","datasetId":7797595},{"sourceId":12367616,"sourceType":"datasetVersion","datasetId":7797750}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. 라이브러리 및 데이터 전처리\nfrom torch.utils.data import Dataset, DataLoader, random_split  # Dataset(클래스 상속), DataLoader(데이터 배치화), random_split(데이터셋 분할)\nimport pandas as pd  # 표 형태의 데이터(csv 등) 읽기/처리\nimport os  # 파일 경로 조작 등 운영체제 관련 기능\nfrom PIL import Image  # 이미지를 열고 처리하는 라이브러리\nimport torch  # PyTorch의 핵심 라이브러리\nfrom torchvision import transforms  # 이미지 전처리(transform) 기능\nimport torch.nn as nn  # 신경망(Neural Network) 구성 요소\nimport torch.nn.functional as F  # 신경망에서 자주 쓰는 함수들(relu 등)\nfrom torchinfo import summary  # 모델 구조 요약 출력\nimport numpy as np  # 수치 계산, 배열 처리\n\n# transforms.Compose([ ... ]) : 여러 전처리 과정을 순차적으로 적용하는 함수\n# transforms.Resize((64,64)) : 이미지를 (64, 64) 크기로 변환 (높이, 너비)\n# transforms.ToTensor() : 이미지를 PyTorch 텐서(0~1 실수값)로 변환\ntrans = transforms.Compose([\n    transforms.Resize((64,64)),  # (size=(64,64)) : (높이, 너비)로 리사이즈\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 픽셀값을 -1~1로 정규화# () : 추가 인자 없음, 이미지를 텐서로 변환\n])\n\n# 데이터셋 경로 지정\ntarget_folder = \"/kaggle/input/dogs-vs-cats/train/train\"\n# file = \"/kaggle/input/celeba-dataset/list_attr_celeba.csv\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:45:52.951973Z","iopub.execute_input":"2025-07-04T06:45:52.952183Z","iopub.status.idle":"2025-07-04T06:46:00.654736Z","shell.execute_reply.started":"2025-07-04T06:45:52.952156Z","shell.execute_reply":"2025-07-04T06:46:00.654183Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# 2. 커스텀 데이터셋 클래스 정의\n# CatDogDataset(label_file, img_dir, transform=None)\n# img_dir : 이미지가 저장된 폴더 경로\n# transform : 이미지 전처리 함수(옵션)\n\nclass CatDogDataset(Dataset):\n    def __init__(self, img_dir, transform=None):        \n        self.img_dir = img_dir\n        self.transform = transform\n        # 2. 이미지 파일 리스트 만들기\n        # 이유: 폴더 내의 모든 이미지 파일명을 리스트로 저장해야 함\n        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n\n    def __getitem__(self, idx):\n        # 파일명 추출\n        img_name = self.img_files[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n        # self.img_dir : 폴더 경로\n\n        # 이미지 열기\n        img = Image.open(img_path).convert(\"RGB\")\n\n        # 3. 라벨 추출 방식 변경\n        # 이유: 파일명에 'cat'이 있으면 0, 'dog'이 있으면 1로 라벨을 부여\n        label = 0 if 'cat' in img_name else 1\n\n        # transform이 지정되어 있다면 적용\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n        \n    def __len__(self): # 전체 이미지 개수 반환\n    # 4. pandas 관련 코드 삭제\n    # 이유: pandas DataFrame이 필요 없음\n        return len(self.img_files)\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T01:58:03.960730Z","iopub.execute_input":"2025-07-04T01:58:03.961024Z","iopub.status.idle":"2025-07-04T01:58:03.966754Z","shell.execute_reply.started":"2025-07-04T01:58:03.961004Z","shell.execute_reply":"2025-07-04T01:58:03.965942Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 3. 데이터셋 분할 및 DataLoader 생성\n# random_split(dataset, lengths, generator)\n# dataset : 전체 데이터셋\n# lengths : 분할할 데이터 개수 리스트\n# generator : 난수 시드(재현성 보장)\n\nfrom torch.utils.data import random_split\nfull_dataset = CatDogDataset(target_folder, trans)\ntotal_len = len(full_dataset)\nval_len = int(total_len * 0.2)  # 20%를 검증용으로\ntrain_len = total_len - val_len\n\ngen = torch.Generator().manual_seed(42)\ntrain_dataset, val_dataset = random_split(full_dataset, [train_len, val_len], generator=gen)\n\n\nfrom torch.utils.data import DataLoader\n# DataLoader(dataset, batch_size, shuffle)\n# dataset : 데이터셋 객체\n# batch_size : 한 번에 불러올 데이터 개수\n# shuffle : 데이터 순서 섞기 여부(학습 시 True)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=True)\n\n\nclass TestDataset(Dataset):\n    def __init__(self, img_dir, transform=None):\n        self.img_paths = []\n        self.labels = []\n        # 클래스 폴더 순회: cats=0, dogs=1\n        for label, folder in enumerate(['cats', 'dogs']):\n            folder_path = os.path.join(img_dir, folder)\n            for fname in os.listdir(folder_path):\n                if fname.endswith('.jpg'):\n                    self.img_paths.append(os.path.join(folder_path, fname))\n                    self.labels.append(label)\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        img = Image.open(self.img_paths[idx]).convert(\"RGB\")\n        label = self.labels[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label  # 이미지와 라벨 반환\n\n    def __len__(self):\n        return len(self.img_paths)\n\ntest_folder = \"/kaggle/input/test-set/test_set\"\ntest_dataset = TestDataset(test_folder, trans)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T03:19:21.738319Z","iopub.execute_input":"2025-07-04T03:19:21.738817Z","iopub.status.idle":"2025-07-04T03:19:21.780708Z","shell.execute_reply.started":"2025-07-04T03:19:21.738795Z","shell.execute_reply":"2025-07-04T03:19:21.779529Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3262584447.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_labeled_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'evaluate_labeled_test' is not defined"],"ename":"NameError","evalue":"name 'evaluate_labeled_test' is not defined","output_type":"error"}],"execution_count":39},{"cell_type":"code","source":"# 4. 디바이스 설정(GPU/CPU)\n# torch.cuda.is_available() : GPU 사용 가능 여부 반환(True/False)\n# torch.device(type) : 사용할 디바이스 지정('cuda' 또는 'cpu')\n\nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')  # GPU 사용\nelse:\n    DEVICE = torch.device('cpu')   # CPU 사용\nprint('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T01:59:36.593005Z","iopub.execute_input":"2025-07-04T01:59:36.593271Z","iopub.status.idle":"2025-07-04T01:59:36.668829Z","shell.execute_reply.started":"2025-07-04T01:59:36.593252Z","shell.execute_reply":"2025-07-04T01:59:36.668096Z"}},"outputs":[{"name":"stdout","text":"Using PyTorch version: 2.6.0+cu124  Device: cuda\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 5. CNN 모델 정의\n# nn.Conv2d(in_channels, out_channels, kernel_size, padding)\n#   in_channels : 입력 채널 수(RGB=3)\n#   out_channels : 출력 채널 수(특징맵 개수)\n#   kernel_size : 필터(커널) 크기\n#   padding : 가장자리 0으로 채우는 픽셀 수\n\n# nn.MaxPool2d(kernel_size, stride)\n#   kernel_size : 풀링 영역 크기\n#   stride : 이동 간격\n\n# nn.Linear(in_features, out_features)\n#   in_features : 입력 벡터 크기\n#   out_features : 출력 벡터 크기\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # 첫 번째 합성곱: 입력 3채널(RGB), 출력 16채널, 3x3 커널\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        # 두 번째 합성곱: 입력 16채널, 출력 32채널, 3x3 커널\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        # 최대풀링: 2x2 영역, 크기 절반으로 축소\n        self.pool = nn.MaxPool2d(2, 2)\n        # 완전연결층: 16*16*32(풀링 후 feature map 크기) → 128\n        self.fc1 = nn.Linear(16*16*32, 128)\n        self.fc2 = nn.Linear(128, 1)  # 이진 분류(출력 1개)\n\n    def forward(self, x):\n        # 합성곱 → ReLU → 풀링 (은닉층에는 ReLU 사용)\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        # feature map 펼치기\n        x = x.view(-1, 16*16*32)\n        x = F.relu(self.fc1(x))\n        # 출력층에는 Sigmoid 사용 (이진 분류 확률값)\n        x = torch.sigmoid(self.fc2(x))\n        return x\n\n# 만약 LeakyReLU를 쓰고 싶다면 아래처럼 수정\n# x = self.pool(F.leaky_relu(self.conv1(x), negative_slope=0.01))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:06:57.272996Z","iopub.execute_input":"2025-07-04T02:06:57.273714Z","iopub.status.idle":"2025-07-04T02:06:57.279564Z","shell.execute_reply.started":"2025-07-04T02:06:57.273682Z","shell.execute_reply":"2025-07-04T02:06:57.278885Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 6. 모델, 손실함수, 옵티마이저 설정\ninput_shape = 3, \n# model.to(DEVICE) : 모델을 지정한 디바이스(GPU/CPU)로 이동\n# torch.optim.Adam(params, lr) : Adam 옵티마이저 생성\n#   params : 모델 파라미터\n#   lr : 학습률\n# nn.BCELoss() : 이진 분류용 손실함수(예측값과 실제값 차이 계산)\n# summary(model, input_size) : 모델 구조와 파라미터 개수 요약\nmodel = CNN().to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.BCELoss()\nBATCH_SIZE = 128\nEPOCHS = 10\nsummary(model, input_size=(32,3,64,64))  # (배치크기, 채널, 높이, 너비)64, 64)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:08:07.348977Z","iopub.execute_input":"2025-07-04T02:08:07.349242Z","iopub.status.idle":"2025-07-04T02:08:08.136918Z","shell.execute_reply.started":"2025-07-04T02:08:07.349220Z","shell.execute_reply":"2025-07-04T02:08:08.136312Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nCNN                                      [32, 1]                   --\n├─Conv2d: 1-1                            [32, 16, 64, 64]          448\n├─MaxPool2d: 1-2                         [32, 16, 32, 32]          --\n├─Conv2d: 1-3                            [32, 32, 32, 32]          4,640\n├─MaxPool2d: 1-4                         [32, 32, 16, 16]          --\n├─Linear: 1-5                            [32, 128]                 1,048,704\n├─Linear: 1-6                            [32, 1]                   129\n==========================================================================================\nTotal params: 1,053,921\nTrainable params: 1,053,921\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 244.33\n==========================================================================================\nInput size (MB): 1.57\nForward/backward pass size (MB): 25.20\nParams size (MB): 4.22\nEstimated Total Size (MB): 30.99\n=========================================================================================="},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# 7. 학습 함수 정의\n# train(model, train_loader, optimizer, criterion, device, epoch, log_interval, batch_size)\n#   model : 학습할 모델\n#   train_loader : 학습 데이터 로더\n#   optimizer : 파라미터 업데이트 방법\n#   criterion : 손실함수\n#   device : 연산 디바이스\n#   epoch : 현재 에폭 번호\n#   log_interval : 학습 상태 출력 주기\n#   batch_size : 배치 크기\n\ndef train(model, train_loader, optimizer, criterion, device, epoch, log_interval, batch_size):\n    model.train()  # 모델을 학습 모드로 설정 (Dropout, BatchNorm 등 활성화)\n    correct = 0    # 올바르게 예측한 샘플 개수\n    train_loss = 0 # 전체 학습 손실 누적\n    total_samples = 0  # 전체 학습 샘플 개수 누적\n\n    for batch_idx, (image, label) in enumerate(train_loader):\n        image = image.to(device)         # 이미지를 지정한 디바이스(GPU/CPU)로 이동\n        label = label.to(device)         # 라벨도 디바이스로 이동\n\n        optimizer.zero_grad()            # 이전 미분값(gradient) 초기화\n        output = model(image)[:,0]       # 모델에 이미지 입력, 예측값(확률) 반환\n                                         # (batch_size, 1) → (batch_size,)로 변환\n\n        loss = criterion(output, label.float())  # 손실함수 계산 (예측값 vs 실제값)\n        train_loss += loss.item() * label.size(0)  # 손실 누적 (배치별 평균 * 배치 크기)\n        loss.backward()                    # 손실에 대한 미분(gradient) 계산\n        optimizer.step()                   # 파라미터 업데이트\n\n        preds = (output >= 0.5).float()    # 예측값이 0.5 이상이면 1(개), 아니면 0(고양이)\n        correct += (preds == label).float().sum().item()  # 맞춘 샘플 개수 누적\n        total_samples += label.size(0)     # 전체 샘플 개수 누적\n\n        # log_interval마다 학습 상태 출력\n        if batch_idx % log_interval == 0:\n            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n                epoch, batch_idx * image.size(0),\n                len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n                loss.item()))\n\n    train_loss /= total_samples           # 전체 평균 손실 계산\n    train_accuracy = 100. * correct / total_samples  # 전체 정확도(%) 계산\n    return train_loss, train_accuracy     # 평균 손실, 정확도 반환","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:11:23.585186Z","iopub.execute_input":"2025-07-04T02:11:23.585963Z","iopub.status.idle":"2025-07-04T02:11:23.595206Z","shell.execute_reply.started":"2025-07-04T02:11:23.585932Z","shell.execute_reply":"2025-07-04T02:11:23.594481Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def evaluate(model, loader):\n    \"\"\"\n    모델의 성능(손실, 정확도)을 평가하는 함수\n    loader: 검증(val) 또는 테스트(test) 데이터 로더\n    \"\"\"\n    model.eval()  # 평가 모드로 전환 (Dropout/BatchNorm 등 비활성화)\n    total_loss = 0  # 전체 손실 누적 변수\n    correct = 0     # 올바른 예측 개수 누적 변수\n    total_samples = 0  # 전체 샘플 개수 누적 변수\n\n    with torch.no_grad():  # 평가 시 그래디언트 계산 비활성화 (속도↑, 메모리↓)\n        for images, labels in loader:  # 배치 단위로 데이터 반복\n            images = images.to(DEVICE)  # 이미지를 지정한 디바이스(GPU/CPU)로 이동\n            labels = labels.to(DEVICE)  # 라벨도 디바이스로 이동\n            outputs = model(images).reshape(-1)  # 모델 예측값, (batch, 1) → (batch,)로 변환\n            loss = criterion(outputs, labels.float())  # 손실값 계산 (예측 vs 실제)\n            total_loss += loss.item() * labels.size(0)  # 배치 손실 * 배치 크기만큼 누적\n            preds = (outputs >= 0.5).float()  # 0.5 이상이면 1, 미만이면 0 (이진 분류)\n            correct += (preds == labels).float().sum().item()  # 맞춘 개수 누적\n            total_samples += labels.size(0)  # 전체 샘플 개수 누적\n\n    avg_loss = total_loss / total_samples  # 전체 평균 손실\n    accuracy = 100. * correct / total_samples  # 전체 정확도(%)\n    return avg_loss, accuracy  # 평균 손실, 정확도 반환\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:14:17.973257Z","iopub.execute_input":"2025-07-04T02:14:17.973525Z","iopub.status.idle":"2025-07-04T02:14:17.979374Z","shell.execute_reply.started":"2025-07-04T02:14:17.973505Z","shell.execute_reply":"2025-07-04T02:14:17.978601Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class early_stopping:\n    def __init__(self, patience, verbose, delta, path='checkpoint.pt'):\n        \"\"\"\n        조기 종료(early stopping) 클래스 초기화\n        patience: 개선 없을 때 기다릴 에폭 수\n        verbose: 개선 시 메시지 출력 여부\n        delta: 개선으로 인정할 최소 변화량\n        path: 모델 저장 경로\n        \"\"\"\n        self.patience = patience  # 개선 없을 때 기다릴 에폭 수\n        self.verbose = verbose    # 개선 시 메시지 출력 여부\n        self.delta = delta        # 개선으로 인정할 최소 변화량\n        self.count = 0            # 개선 없는 에폭 수 카운트\n        self.best_score = None    # 최고 성능(최소 val loss) 기록\n        self.early_stop = False   # 조기 종료 여부 플래그\n        self.val_loss_min = np.inf # 최소 검증 손실값(초기값: 무한대)\n        self.path = path          # 모델 저장 경로\n\n    def __call__(self, val_loss, model):\n        \"\"\"\n        에폭마다 호출되는 메서드\n        val_loss: 현재 검증 손실\n        model: 현재 모델\n        \"\"\"\n        score = -val_loss  # 손실이 작을수록 score는 커짐(최소화 문제이므로 부호 반전)\n        if self.best_score is None:  # 첫 에폭(최초 기록)\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)  # 모델 저장\n        elif score < self.best_score + self.delta:\n            # 개선이 없으면 카운트 증가\n            self.count += 1\n            if self.verbose:\n                print(f\"Early Stopping counter: {self.count} out of {self.patience}\")\n            if self.count >= self.patience:  # patience만큼 개선 없으면 종료\n                self.early_stop = True\n        else:\n            # 개선된 경우: 모델 저장, 카운트 리셋\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.count = 0\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"\n        성능이 개선되면 모델을 저장하는 함수\n        val_loss: 현재 검증 손실\n        model: 현재 모델\n        \"\"\"\n        if self.verbose:\n            print(f\"Validation loss decreased ({self.val_loss_min:.6f}) --> {val_loss:.6f}. saving model..\")\n        torch.save(model.state_dict(), self.path)  # 모델 파라미터 저장\n        self.val_loss_min = val_loss  # 최소 손실 갱신\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:15:28.715738Z","iopub.execute_input":"2025-07-04T02:15:28.716010Z","iopub.status.idle":"2025-07-04T02:15:28.723265Z","shell.execute_reply.started":"2025-07-04T02:15:28.715992Z","shell.execute_reply":"2025-07-04T02:15:28.722526Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# 10. 학습 루프 (모델 학습 및 평가)\n# for epoch in range(1, EPOCHS + 1)\n#   epoch : 현재 에폭 번호 (1부터 EPOCHS까지 반복)\n\nearlystop = early_stopping(patience=2, verbose=True, path='best_model.pt', delta=0)\nloss_hist_train     = [0] * EPOCHS\naccuracy_hist_train = [0] * EPOCHS\nloss_hist_valid     = [0] * EPOCHS\naccuracy_hist_valid = [0] * EPOCHS\n\nfor epoch in range(1, EPOCHS + 1):\n    # 학습 데이터로 모델 학습\n    loss_, acc_ = train(model, train_loader, optimizer, criterion, DEVICE, epoch, log_interval=200, batch_size=BATCH_SIZE)\n    loss_hist_train[epoch-1] = loss_\n    accuracy_hist_train[epoch-1] = acc_\n\n    # 검증 데이터로 모델 성능 평가\n    val_loss, val_accuracy = evaluate(model, val_loader)\n    loss_hist_valid[epoch-1] = val_loss\n    accuracy_hist_valid[epoch-1] = val_accuracy\n\n    print(\"\\n[EPOCH: {}], \\tVal Loss: {:.4f}, \\tVal Accuracy: {:.2f} % \\n\".format(\n        epoch, val_loss, val_accuracy))\n\n    # 조기 종료 체크 (검증 손실 기준)\n    earlystop(val_loss, model)\n    if earlystop.early_stop:\n        print(\"Early stopping\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:18:53.493257Z","iopub.execute_input":"2025-07-04T02:18:53.494019Z","iopub.status.idle":"2025-07-04T02:28:39.949573Z","shell.execute_reply.started":"2025-07-04T02:18:53.493989Z","shell.execute_reply":"2025-07-04T02:28:39.948906Z"}},"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/20000 (0%)]\tTrain Loss: 0.689848\nTrain Epoch: 1 [6400/20000 (32%)]\tTrain Loss: 0.637448\nTrain Epoch: 1 [12800/20000 (64%)]\tTrain Loss: 0.532497\nTrain Epoch: 1 [19200/20000 (96%)]\tTrain Loss: 0.487401\n\n[EPOCH: 1], \tVal Loss: 0.5416, \tVal Accuracy: 73.72 % \n\nValidation loss decreased (inf) --> 0.541609. saving model..\nTrain Epoch: 2 [0/20000 (0%)]\tTrain Loss: 0.535786\nTrain Epoch: 2 [6400/20000 (32%)]\tTrain Loss: 0.440299\nTrain Epoch: 2 [12800/20000 (64%)]\tTrain Loss: 0.546847\nTrain Epoch: 2 [19200/20000 (96%)]\tTrain Loss: 0.485010\n\n[EPOCH: 2], \tVal Loss: 0.4716, \tVal Accuracy: 77.86 % \n\nValidation loss decreased (0.541609) --> 0.471588. saving model..\nTrain Epoch: 3 [0/20000 (0%)]\tTrain Loss: 0.297984\nTrain Epoch: 3 [6400/20000 (32%)]\tTrain Loss: 0.448337\nTrain Epoch: 3 [12800/20000 (64%)]\tTrain Loss: 0.607191\nTrain Epoch: 3 [19200/20000 (96%)]\tTrain Loss: 0.408012\n\n[EPOCH: 3], \tVal Loss: 0.4606, \tVal Accuracy: 78.46 % \n\nValidation loss decreased (0.471588) --> 0.460585. saving model..\nTrain Epoch: 4 [0/20000 (0%)]\tTrain Loss: 0.368784\nTrain Epoch: 4 [6400/20000 (32%)]\tTrain Loss: 0.259741\nTrain Epoch: 4 [12800/20000 (64%)]\tTrain Loss: 0.416341\nTrain Epoch: 4 [19200/20000 (96%)]\tTrain Loss: 0.348238\n\n[EPOCH: 4], \tVal Loss: 0.4647, \tVal Accuracy: 78.34 % \n\nEarly Stopping counter: 1 out of 2\nTrain Epoch: 5 [0/20000 (0%)]\tTrain Loss: 0.303736\nTrain Epoch: 5 [6400/20000 (32%)]\tTrain Loss: 0.193514\nTrain Epoch: 5 [12800/20000 (64%)]\tTrain Loss: 0.208186\nTrain Epoch: 5 [19200/20000 (96%)]\tTrain Loss: 0.258651\n\n[EPOCH: 5], \tVal Loss: 0.4595, \tVal Accuracy: 79.26 % \n\nValidation loss decreased (0.460585) --> 0.459537. saving model..\nTrain Epoch: 6 [0/20000 (0%)]\tTrain Loss: 0.561442\nTrain Epoch: 6 [6400/20000 (32%)]\tTrain Loss: 0.376438\nTrain Epoch: 6 [12800/20000 (64%)]\tTrain Loss: 0.261085\nTrain Epoch: 6 [19200/20000 (96%)]\tTrain Loss: 0.342196\n\n[EPOCH: 6], \tVal Loss: 0.4940, \tVal Accuracy: 77.70 % \n\nEarly Stopping counter: 1 out of 2\nTrain Epoch: 7 [0/20000 (0%)]\tTrain Loss: 0.425956\nTrain Epoch: 7 [6400/20000 (32%)]\tTrain Loss: 0.172795\nTrain Epoch: 7 [12800/20000 (64%)]\tTrain Loss: 0.224056\nTrain Epoch: 7 [19200/20000 (96%)]\tTrain Loss: 0.274977\n\n[EPOCH: 7], \tVal Loss: 0.5094, \tVal Accuracy: 79.66 % \n\nEarly Stopping counter: 2 out of 2\nEarly stopping\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, img_dir, transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n        print(self.img_files[:5])  # 파일명 5개 출력\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:40:50.852186Z","iopub.execute_input":"2025-07-04T02:40:50.852873Z","iopub.status.idle":"2025-07-04T02:40:50.857516Z","shell.execute_reply.started":"2025-07-04T02:40:50.852850Z","shell.execute_reply":"2025-07-04T02:40:50.856714Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"for images, img_names in test_loader:\n    print(img_names)  # 실제로 파일명이 출력되는지 확인\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:40:48.065021Z","iopub.execute_input":"2025-07-04T02:40:48.065287Z","iopub.status.idle":"2025-07-04T02:40:48.311166Z","shell.execute_reply.started":"2025-07-04T02:40:48.065265Z","shell.execute_reply":"2025-07-04T02:40:48.310348Z"}},"outputs":[{"name":"stdout","text":"('7981.jpg', '6234.jpg', '1269.jpg', '3863.jpg', '6241.jpg', '10304.jpg', '623.jpg', '2193.jpg', '11925.jpg', '3750.jpg', '11378.jpg', '2008.jpg', '10730.jpg', '5982.jpg', '7737.jpg', '2081.jpg', '10597.jpg', '6588.jpg', '10054.jpg', '7966.jpg', '3919.jpg', '6197.jpg', '10924.jpg', '6399.jpg', '9960.jpg', '3757.jpg', '9131.jpg', '9620.jpg', '9062.jpg', '4489.jpg', '3138.jpg', '10213.jpg')\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# 11. 라벨링 된 테스트 데이터셋 성능평가\n\ntest_loss, test_acc = evaluate(model, test_loader)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T03:25:40.543090Z","iopub.execute_input":"2025-07-04T03:25:40.543878Z","iopub.status.idle":"2025-07-04T03:25:45.996759Z","shell.execute_reply.started":"2025-07-04T03:25:40.543850Z","shell.execute_reply":"2025-07-04T03:25:45.996016Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.3317, Test Accuracy: 86.01%\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# 12. 이미지를 입력하면 판별해주는 드드\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\n\n# 1. 이미지 전처리 함수 (학습 때와 동일하게 맞추세요)\ntrans = transforms.Compose([\n    transforms.Resize((64, 64)),  # 이미지 크기 맞추기\n    transforms.ToTensor(),        # 텐서 변환\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 정규화\n])\n\ndef predict_single_image(model, image_path, transform, device):\n    \"\"\"\n    단일 이미지에 대해 고양이(cat)인지 개인지(dog)인지 예측하는 함수\n    model : 학습된 PyTorch 모델\n    image_path : 예측할 이미지 파일 경로\n    transform : 이미지 전처리 함수\n    device : 연산 디바이스 (cpu 또는 cuda)\n    \"\"\"\n    model.eval()  # 평가 모드로 전환\n    image = Image.open(image_path).convert('RGB')  # 이미지 열기\n    image = transform(image)  # 전처리 적용\n    image = image.unsqueeze(0)  # 배치 차원 추가 (1, C, H, W)\n    image = image.to(device)  # 디바이스 이동\n\n    with torch.no_grad():  # 그래디언트 계산 비활성화\n        output = model(image).reshape(-1)  # (1, 1) → (1,)\n        prob = output.item()  # 확률값 추출\n\n    # 0~1 확률 기준으로 0.5 이상이면 dog, 미만이면 cat\n    label = 'dog' if prob >= 0.5 else 'cat'\n    return label, prob\n\n# 사용 예시\n# label, probability = predict_single_image(model, '/kaggle/working/sample_image.jpg', trans, DEVICE)\n# print(f'Prediction: {label}, Probability: {probability:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T03:45:11.266142Z","iopub.execute_input":"2025-07-04T03:45:11.266750Z","iopub.status.idle":"2025-07-04T03:45:11.273010Z","shell.execute_reply.started":"2025-07-04T03:45:11.266726Z","shell.execute_reply":"2025-07-04T03:45:11.272199Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"label, probability = predict_single_image(model, \"/kaggle/input/sample/sample_image.jpg\", trans, DEVICE)\nprint(f'Prediction: {label}, Probability: {probability:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T03:46:52.906264Z","iopub.execute_input":"2025-07-04T03:46:52.906754Z","iopub.status.idle":"2025-07-04T03:46:53.122146Z","shell.execute_reply.started":"2025-07-04T03:46:52.906729Z","shell.execute_reply":"2025-07-04T03:46:53.121503Z"}},"outputs":[{"name":"stdout","text":"Prediction: dog, Probability: 0.9922\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# 12. 최종 테스트 데이터셋에 대한 예측 및 제출 파일 생성\nimport torch\nimport pandas as pd\nimport os\n\n\n# 1. 조기 종료로 저장된 최적 모델 불러오기\nmodel.load_state_dict(torch.load('best_model.pt'))  # best_model.pt 파일이 /kaggle/working/에 있는지 확인\nmodel.eval()  # 평가 모드로 전환 (Dropout/BatchNorm 등 비활성화)\n\nresults = []      # 예측 확률값을 저장할 리스트\nimage_ids = []    # 이미지 id(숫자)를 저장할 리스트\n\nwith torch.no_grad():  # 평가 시에는 그래디언트 계산을 끔 (속도↑, 메모리↓)\n    for images, img_names in test_loader:  # test_loader는 (이미지, 파일명) 반환\n        images = images.to(DEVICE)  # 이미지를 GPU/CPU로 이동\n        outputs = model(images).reshape(-1)  # (batch, 1) → (batch,)로 변환\n        probs = outputs.cpu().numpy()  # GPU → CPU로 이동 후 numpy 배열로 변환\n        results.extend(probs)  # 예측 확률을 리스트에 추가\n        # 파일명에서 숫자(id)만 추출 (예: '1234.jpg' → 1234)\n        ids = [int(name.split('.')[0]) for name in img_names]\n        image_ids.extend(ids)  # 이미지 id 리스트에 추가\n\n# 2. 결과를 id 기준으로 정렬 (Kaggle 제출 포맷에 맞추기)\nsubmission = pd.DataFrame({'id': image_ids, 'label': results})  # DataFrame 생성\nsubmission = submission.sort_values('id')  # id 순서대로 정렬\n\n# 3. 파일 저장 경로 지정 (Kaggle 환경에서는 /kaggle/working/ 권장)\nsave_path = '/kaggle/working/submission.csv'\nsubmission.to_csv(save_path, index=False)  # CSV 파일로 저장\n\n# 4. 저장 확인 및 미리보기\nif os.path.exists(save_path):\n    df = pd.read_csv(save_path)  # 저장된 파일 불러오기\n    print(\"파일이 정상적으로 저장되었습니다.\")\n    print(df.head())  # 상위 5개 데이터 미리보기\nelse:\n    print(\"파일이 저장되지 않았습니다. 경로와 저장 코드를 다시 확인하세요.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T03:24:19.300346Z","iopub.execute_input":"2025-07-04T03:24:19.300630Z","iopub.status.idle":"2025-07-04T03:24:19.423612Z","shell.execute_reply.started":"2025-07-04T03:24:19.300610Z","shell.execute_reply":"2025-07-04T03:24:19.422574Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3137709138.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 예측 확률을 리스트에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# 파일명에서 숫자(id)만 추출 (예: '1234.jpg' → 1234)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mimage_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 이미지 id 리스트에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/3137709138.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 예측 확률을 리스트에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# 파일명에서 숫자(id)만 추출 (예: '1234.jpg' → 1234)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mimage_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 이미지 id 리스트에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: split_with_sizes(): argument 'split_sizes' (position 2) must be tuple of ints, not str"],"ename":"TypeError","evalue":"split_with_sizes(): argument 'split_sizes' (position 2) must be tuple of ints, not str","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"# 13. 제출 파일(예측 결과) 분석 및 인사이트 도출\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 1. 제출 파일 불러오기\ndf = pd.read_csv('submission.csv')  # 예측 결과가 저장된 CSV 파일\n\n# 2. 예측 확률 분포 통계 확인\nprint(df['label'].describe())  # 예측값의 평균, 표준편차 등 기본 통계\n\n# 3. 예측 확률 분포 시각화\nplt.hist(df['label'], bins=50)\nplt.title('Distribution of predicted probabilities')\nplt.xlabel('Predicted probability (dog)')\nplt.ylabel('Number of images')\nplt.show()\n\n# 4. 불확실(0.4~0.6) 예측 샘플 확인\nuncertain = df[(df['label'] > 0.4) & (df['label'] < 0.6)]\nprint(f\"Number of uncertain predictions: {len(uncertain)}\")\nprint(uncertain.head())\n\n# 5. 분석 결과를 바탕으로 개선 아이디어를 메모/정리\n# 예) 확률 분포가 한쪽에 치우쳤다면 클래스 불균형, 증강 부족, 모델 단순함 등을 의심\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T02:44:26.379461Z","iopub.execute_input":"2025-07-04T02:44:26.379762Z","iopub.status.idle":"2025-07-04T02:44:26.586774Z","shell.execute_reply.started":"2025-07-04T02:44:26.379739Z","shell.execute_reply":"2025-07-04T02:44:26.585988Z"}},"outputs":[{"name":"stdout","text":"count    12500.000000\nmean         0.556026\nstd          0.355960\nmin          0.000072\n25%          0.200056\n50%          0.602778\n75%          0.917201\nmax          1.000000\nName: label, dtype: float64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Number of uncertain predictions: 1420\n    id     label\n12  13  0.513048\n28  29  0.503794\n32  33  0.558571\n50  51  0.523675\n54  55  0.443613\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}