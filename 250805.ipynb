{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce84d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894366b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths= (\"https://news.naver.com/section/101\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"sa_text\", \"sa_item_SECTION_HEADLINE\")\n",
    "        )\n",
    "    )\n",
    ")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e58f1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658eca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31cbd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\"k\" : 1, \"fetch_k\" : 4}\n",
    ")\n",
    "\n",
    "prompt = hub.pull(\"sungwoo/ragbasic\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#gpt-4o-mini\n",
    "llm = ChatOpenAI(model_name=\"chatgpt-4o-latest\", temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e16e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "chain = (\n",
    "    {\n",
    "        \"context\" : retriever | RunnableLambda(lambda x : \"\\n\\n\".join(d.page_content for d in docs)),\n",
    "        \"question\" : RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    " \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b858e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"오늘 증시는 에코프로비엠의 실적 호조와 이차전지 업종 반등 기대감 등으로 상승세를 보였습니다. 에코프로비엠은 2분기 영업이익이 전년 대비 1155% 증가하며 '어닝 서프라이즈'를 기록했습니다. 이차전지 관련주 중심으로 투자심리가 회복되는 분위기입니다.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"오늘 증시는?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1316be5e",
   "metadata": {},
   "source": [
    "### 페르소나 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fbfdbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. 향후 금리는 어떻게 변동할 것으로 예상되나요?  ',\n",
       " '2. 중앙은행의 정책에 따라 금리가 오를 가능성이 있나요?  ',\n",
       " '3. 경제 지표를 고려할 때 금리 추세는 어떤 방향인가요?  ',\n",
       " '4. 단기 및 장기 금리 전망에 어떤 차이가 있나요?  ',\n",
       " '5. 인플레이션과 경기 상황이 금리에 어떤 영향을 줄까요?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"\n",
    "당신은 AI 언어 모델 조수입니다. 당신의 임무는 주어진 사용자 질문에 대해 벡터 데이터베이스에서 관련 문서를 검색할 수 있도록 다섯 가지 다른 버전을 생성하는 것입니다.\n",
    "사용자 질문에 대한 여러 관점을 생성함으로써, 거리 기반 유사성 검색의 한계를 극복하는 데 도움을 주는 것이 목표입니다.\n",
    "각 질문은 새 줄로 구분하여 제공하세요. 원본 질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x : x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "\n",
    "generate_queries.invoke(\"금리의 전망\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781040da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "def get_unique_union(documents: list[list]):\n",
    "    tmp = []\n",
    "    for sublist in documents:\n",
    "        for doc in sublist:\n",
    "            tmp.append(dumps(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8c0877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    # tmp = []\n",
    "    # for sublist in documents:\n",
    "    #     for doc in sublist:\n",
    "    #         tmp.append(dumps(doc))\n",
    "    unique_doc = list(set([dumps(doc) for sublist in documents for doc in sublist]))\n",
    "       \n",
    "    return [loads(doc) for doc in unique_doc]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "retriever_chain = generate_queries | retriever.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bea858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =retriever_chain.invoke({\"question\" : \"금리 전망은?\"})\n",
    "template = \"\"\"다음 맥락을 바탕으로 질문에 답변하세요:\n",
    "\n",
    "\n",
    "{context}\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22ff17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"다음 맥락을 바탕으로 질문에 답변하세요:\n",
    "\n",
    "\n",
    "{context}\n",
    "\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "fina_chain = (\n",
    "    {'context' : retriever_chain, 'question' : RunnablePassthrough()}\n",
    "    | prompt | llm | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1ef238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자의 주가가 최근 ‘7만전자’로 회복되면서 투자자들 사이에서 향후 주가 전망에 대한 의견이 엇갈리고 있습니다. 일부 투자자들은 현재 수익 구간에 진입한 만큼 차익 실현을 고려하며 ‘떠나자’는 입장을 보이고 있고, 다른 한편에서는 향후 추가 상승 가능성을 기대하며 ‘기다리자’는 입장을 고수하고 있습니다.\\n\\n이러한 상황은 삼성전자의 주가가 단기적으로는 심리적 저항선인 7만 원대를 회복했지만, 향후 실적 개선, 반도체 업황 회복, 글로벌 경제 상황 등 다양한 변수에 따라 주가가 추가 상승할지 여부가 결정될 수 있음을 시사합니다.\\n\\n따라서 삼성전자의 주가 전망은 긍정적인 기대와 신중한 관망이 공존하는 상황으로, 투자자들은 시장 흐름과 기업 실적 등을 면밀히 살펴보며 판단할 필요가 있습니다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fina_chain.invoke(\"삼성전자의 주가 전망\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a17f81",
   "metadata": {},
   "source": [
    "## Rag chatbot \n",
    "\n",
    "tavily 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "from langchain_core.messages.chat import ChatMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableMap\n",
    "from langchain_ollama import ChatOllama\n",
    "import os \n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_core.prompts import loading\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import base64 \n",
    "from PIL import Image \n",
    "import io\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from operator import itemgetter \n",
    "from dotenv import load_dotenv\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class Route(str, Enum):\n",
    "    langchain_document = 'langchain_document'\n",
    "    web = \"web\"\n",
    "\n",
    "class RouteOutput(BaseModel):\n",
    "    route: Route\n",
    "\n",
    "\n",
    "\n",
    "web_retriever = TavilySearchAPIRetriever(k=10).with_config({'run_name' : 'web_retriver'})\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "if os.path.isdir(\"./mycache\") == False:\n",
    "    os.mkdir(\"./mycache\")\n",
    "\n",
    "if os.path.isdir(\"./mycache/files\") == False:\n",
    "    os.mkdir(\"./mycache/files\")\n",
    "    \n",
    "if os.path.isdir(\"./mycache/embedding\") == False:\n",
    "    os.mkdir(\"./mycache/embedding\")\n",
    "    \n",
    "store = LocalFileStore(\"./mycache/embedding\")\n",
    "\n",
    "if 'chain' not in st.session_state:\n",
    "    st.session_state['chain'] = None \n",
    "\n",
    "if 'messages' not in st.session_state:\n",
    "    st.session_state['messages'] = []\n",
    "\n",
    "def add_message(role, message):\n",
    "    st.session_state['messages'].append({\"role\": role, \"content\": message})\n",
    "\n",
    "st.title(\"RAG 기반 챗봇\")\n",
    "\n",
    "with st.sidebar:\n",
    "    uploaded_file = st.file_uploader(\"파일 업로드\", type=['pdf', 'txt'])\n",
    "\n",
    "@st.cache_resource(show_spinner=\"업로드 파일 처리중 기다리세요\")\n",
    "def processing(file):\n",
    "    if file.name.split(\".\")[-1] == \"pdf\":\n",
    "        file_contents = file.read()\n",
    "        #파일 저장\n",
    "        with open(f\"./mycache/files/{file.name}\", \"wb\") as f:\n",
    "            f.write(file_contents)\n",
    "\n",
    "        #파일 임베딩 \n",
    "        # insert your code \n",
    "        loader = PDFPlumberLoader(f\"./mycache/files/{file.name}\")\n",
    "        docs = loader.load()\n",
    "        text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "        split_documents = text_spliter.split_documents(docs)\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        \n",
    "        cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "                            underlying_embeddings=embeddings, # 기본 임베딩 모델 지정\n",
    "                            document_embedding_cache=store # 로컬 저장소 지정\n",
    "                        )\n",
    "        vectorstore = FAISS.from_documents(documents=split_documents, embedding=cached_embedder)\n",
    "        retriever = vectorstore.as_retriever()\n",
    "            \n",
    "    elif file.name.split(\".\")[-1] == \"txt\":\n",
    "        file_contents = file.read()\n",
    "        #파일 저장\n",
    "        with open(f\"./mycache/files/{file.name}\", \"w\", encoding='utf-8') as f:\n",
    "            f.write(file_contents.decode())\n",
    "        text = file_contents.decode()\n",
    "        text_splitter = SemanticChunker(\n",
    "                OpenAIEmbeddings(),\n",
    "                breakpoint_threshold_type=\"percentile\", # 백분위수 기준\n",
    "                breakpoint_threshold_amount=70, # 임계값 70%\n",
    "            )\n",
    "        split_documents = text_splitter.create_documents([text])\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        \n",
    "        cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "                            underlying_embeddings=embeddings, # 기본 임베딩 모델 지정\n",
    "                            document_embedding_cache=store # 로컬 저장소 지정\n",
    "                        )\n",
    "        vectorstore = FAISS.from_documents(documents=split_documents, embedding=cached_embedder)\n",
    "        retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    #######\n",
    "    return retriever \n",
    "\n",
    "join_docs = RunnableLambda(\n",
    "    lambda docs: \"\\n\".join(doc.page_content for doc in docs)\n",
    ")\n",
    "\n",
    "def print_messages():\n",
    "    for chat_message in st.session_state[\"messages\"]:\n",
    "        st.chat_message(chat_message['role']).write(chat_message['content'])\n",
    "\n",
    "\n",
    "def routed_retriever(inp):\n",
    "    question = inp['question']\n",
    "    route = inp['route']\n",
    "\n",
    "    if route == Route.langchain_document:\n",
    "        return langchain_document_retriever.invoke(question)\n",
    "    elif route == Route.web:\n",
    "        return web_retriever.invoke(question)\n",
    "\n",
    "    raise ValueError(f\"Unkown route: {route}\")\n",
    "\n",
    "\n",
    "def create_chain(retriever):\n",
    "    global langchain_document_retriever\n",
    "    langchain_document_retriever = retriever.with_config({'run_name' : 'langchain_document_retriver'})\n",
    "    prompt_text = {'_type': 'prompt',\n",
    "                'template': \"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved `information` to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nAnswer in Korean.\\n\\n<information>\\n{context} \\n</information>\\n\\n#Question: \\n{question}\\n\\n#Answer:\\n  #chat_history : \\n {chat_history}\",\n",
    "                'input_variables': ['question', 'context', 'chat_history']}\n",
    "    prompt = loading.load_prompt_from_config(prompt_text)\n",
    "    # llm = ChatOllama(model='gemma:7b', temperature=0)\n",
    "    llm = ChatOpenAI( model='gpt-4.1-2025-04-14', temperature=0)\n",
    "\n",
    "    route_prompt  =  ChatPromptTemplate.from_template(\"\"\"   \n",
    "        질문에 답변하기 위한 적절한 Retriever를 선택하세요.\n",
    "\n",
    "        질문: {question}\n",
    "        \"\"\")\n",
    "\n",
    "    route_chain = (\n",
    "        route_prompt | llm.with_structured_output(RouteOutput) \n",
    "        | (lambda x : x.route)\n",
    "    )\n",
    "\n",
    "    chain = (\n",
    "        RunnableMap(\n",
    "            {\n",
    "                \"route\" : route_chain,\n",
    "                \"question\" : itemgetter(\"question\"),\n",
    "                \"chat_history\" : itemgetter('chat_history')\n",
    "            }\n",
    "        )\n",
    "        | RunnablePassthrough.assign(context=routed_retriever)\n",
    "        | prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    # chain = (\n",
    "\n",
    "    #     {\n",
    "    #             \"context\": retriever | join_docs,\n",
    "    #             \"question\": RunnablePassthrough(),\n",
    "    #             \"chat_history\": RunnablePassthrough(),\n",
    "    #     }\n",
    "    #     | prompt\n",
    "    #     | llm\n",
    "    #     | StrOutputParser()\n",
    "    # )\n",
    "    return chain\n",
    "\n",
    "\n",
    "if uploaded_file:\n",
    "    retriever = processing(uploaded_file)\n",
    "    chain = create_chain(retriever)\n",
    "    st.session_state['chain'] = chain \n",
    "\n",
    "\n",
    "options = (\"질문하기\", \"이미지 생성\")\n",
    "\n",
    "selected_radio = st.radio(\n",
    "    '다음 중 하나 선택하세요',\n",
    "    options\n",
    ")\n",
    "\n",
    "if selected_radio == \"질문하기\":\n",
    "\n",
    "    user_input = st.chat_input(\"질문을 하세요\")\n",
    "    print_messages()\n",
    "\n",
    "    if user_input:\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        history_str = \"\\n\".join(\n",
    "                f\"{m['role']} : {m['content']}\" for m in st.session_state.messages )\n",
    "        # print(\"---------------\")\n",
    "        # print(history_str)\n",
    "        # print(\"---------------\")\n",
    "        chain = st.session_state['chain']\n",
    "        \n",
    "        \n",
    "        # print(payload)\n",
    "        if chain is not None:\n",
    "            #히스토리 (과거 질문과 대답 목록 )\n",
    "            \n",
    "            \n",
    "            st.chat_message(\"user\").write(user_input)\n",
    "            # print(\"===>\")\n",
    "            # print(user_input)\n",
    "            payload = {\"question\": user_input, \"chat_history\": history_str}\n",
    "            response = chain.stream(payload)\n",
    "            # add_message('user' , user_input)\n",
    "            # print(response)\n",
    "\n",
    "            with st.chat_message('assistant'):\n",
    "                container = st.empty()\n",
    "\n",
    "                ai_answer = \"\"\n",
    "                for token in response:\n",
    "                    ai_answer += token \n",
    "                    container.markdown(ai_answer)\n",
    "                add_message('assistant', ai_answer)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "elif selected_radio == \"이미지 생성\":\n",
    "    generate_input = st.chat_input(\"생성하고 싶은 이미지를 설명해주세요\")\n",
    "\n",
    "    if generate_input:\n",
    "\n",
    "        response = client.images.generate(\n",
    "                    model='dall-e-3',\n",
    "                    prompt=generate_input,\n",
    "                    size=\"1024x1024\",\n",
    "                    quality = 'standard',\n",
    "                    response_format='b64_json',\n",
    "                    n=1\n",
    "                )\n",
    "        result = response.model_dump()\n",
    "        img = response.data[0]\n",
    "        img_data = base64.b64decode(img.b64_json)\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        st.image(img)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
