{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e96a16-fcc8-43f5-bf1d-ce751b577424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e227b8-afff-42c3-a2eb-8c7af2262e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff00ed-7c7f-4612-b4aa-dfdef11f5634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2aa87c6-6835-4039-bccf-19016ed6dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizer\n",
    "import torch\n",
    "import peft\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bcb2e-2bc5-482f-b2e0-934335308ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5f7aa3-4f71-46d1-8ec7-c9d3fab157e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def cleanup():\n",
    "    if 'model' in globals():\n",
    "        del globals()['model']\n",
    "    if 'dataset' in globals():\n",
    "        del globals()['dataset']\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece08107-44e6-4046-8eee-1d5877a1ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfa60d6-ef59-4734-9b5e-0e0b602df042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef5732a-e705-4922-8c8d-916de30052d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_id, peft=None):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    if peft is None:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map={\"\":0})\n",
    "\n",
    "    elif peft == 'lora':\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,  device_map={\"\":0})\n",
    "        lora_config = LoraConfig(\n",
    "                    r=8,\n",
    "                    lora_alpha=32,\n",
    "                    target_modules=[\n",
    "                                        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                                        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "                                    ],\n",
    "                    lora_dropout=0.05,\n",
    "                    bias=\"none\",\n",
    "                    task_type=\"CAUSAL_LM\"\n",
    "                )\n",
    "\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        model.print_trainable_parameters()\n",
    "\n",
    "    print_gpu_utilization()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582faefc-81fc-4b45-afc7-4a518f116375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def print_gpu_utilization():\n",
    "    if torch.cuda.is_available():\n",
    "        used_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        print(f\"GPU 메모리 사용량: {used_memory:.3f} GB\")\n",
    "    else:\n",
    "        print(\"런타임 유형을 GPU로 변경하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35be251-6f33-4c69-8f48-671d9812b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Bllossom/llama-3.2-Korean-Bllossom-AICA-5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c37c1d4-63d7-4613-9ce2-af781452684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b032816f3614cef8b84104acaa1dd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86982fb304af4a4fbbf4ce49e420a627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f36244d7d144b887610436b917597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18879fe473c141c0ab6a1eb5c95d8298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/835M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aba5e50c7174fec967fc3674023d58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e382cfb658f14f28b00a242817a8219c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9e268cbf6a47e1981c8849b89ae2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15,196,160 || all params: 4,326,660,878 || trainable%: 0.3512\n",
      "GPU 메모리 사용량: 8.088 GB\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(model_id, peft='lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312bba6a-355b-48bd-a775-05acbff76abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [128000, 102612, 114784, 121520, 123151, 105807], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"심장이 매우 뛰어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc41ada2-eb47-4734-bbef-306208a2486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15196160\n",
      "all params: 4326660878\n",
      "trainable%: 0.3512214252165848\n"
     ]
    }
   ],
   "source": [
    "trainable_params = 0\n",
    "all_param = 0\n",
    "for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "\n",
    "print(f\"\"\"trainable params: {trainable_params}\n",
    "all params: {all_param}\n",
    "trainable%: {100 * trainable_params / all_param}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3289d0af-baf9-4198-b944-023b3523822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adf1fd00-045b-451c-963f-12fc4ce89d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de141206072949c69c4da7d81e2c7981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"csv\", data_files={\"train\" : \"./train_data.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c38e9a1e-63b1-4c3e-8dae-716bedf29550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b02387ec0f2479cb751550f22aab15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = data.map(lambda x : {'text' : f\"\"\"User: {x['question']} \n",
    "                    Assistant: {x['answer']}<|endoftext|>\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8faa74-0d8c-4257-9074-707cf0c83649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 10세 소년이 충치 치료를 위해 치과에 방문했다. 치과의사는 수복 재료로 아말감 대신 복합 레진을 권장하고 있다. 복합 레진 사용의 장점으로 가장 적절한 것은?  \n",
      "1) 심미성이 좋다.  \n",
      "2) 수복물의 강도가 높다.  \n",
      "3) 수은 함유로 인한 독성 위험이 있다.  \n",
      "4) 비용이 저렴하다.  \n",
      "5) 이차 우식증 발생 위험이 낮다. \n",
      "                    Assistant: 1) 심미성이 좋다.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for x in data2['train']:\n",
    "    print(x['text'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9ded74-91cd-4153-9cbb-90503f8c7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9accc1b-f019-479b-8037-8c9686bb3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "argu = TrainingArguments(\n",
    "         per_device_train_batch_size=1,\n",
    "        num_train_epochs=2, \n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate = 0.0001,\n",
    "        fp16=True,\n",
    "        output_dir=\"./output/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62725abe-8e76-4845-b63b-7bd0f9721b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7021dc69008d4b5f8f38f6179139444c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = data2.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "703aefc7-44b4-48dc-bacb-3809ced737a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fb17cae-68f3-4f99-b9d6-c74bbe962dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    train_dataset=train_dataset['train'],\n",
    "    args=argu,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3137510d-542a-4a1c-8828-7e5c601b4379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6114' max='6114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6114/6114 1:13:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.401800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.211800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.960700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.948700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6114, training_loss=1.0922917299579475, metrics={'train_runtime': 4420.9497, 'train_samples_per_second': 5.532, 'train_steps_per_second': 1.383, 'total_flos': 9.5783623801107e+16, 'train_loss': 1.0922917299579475, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93c10aab-cb33-40be-a8c0-54eca3e869e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 치주 질환·충치 예방을 위한 우선 권장 구강 관리법 AI 생성 함수(코드 분석)\n",
    "\n",
    "prompt = \"\"\"질문에 해당되는 답변의 번호를 알려주세요\n",
    "\"\"\"\n",
    "\n",
    "from transformers.generation import GenerationConfig\n",
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_special_tokens=True)  # 모델이 생성한 토큰을 실시간 출력(특수 토큰 제외)\n",
    "streamer = TextStreamer(tokenizer)                            # 스트리머 객체(토크나이저 연결, 두 번 정의됨—실행상 영향은 없음)\n",
    "gen_cfg = GenerationConfig.from_model_config(model.config)    # 현재 모델 설정 기반의 생성 파라미터 객체 생성\n",
    "gen_cfg.pad_token_id = tokenizer.eos_token_id                 # 패딩 토큰 id를 eos_token_id로 지정\n",
    "\n",
    "def gen(x):\n",
    "    gen_cfg.temperature = 0.3                                 # 생성 다양성(랜덤성) 감소해 신뢰도 높임\n",
    "    gen_cfg.max_new_tokens = 128                              # 최대 생성 토큰(문장 길이) 제한\n",
    "    rt = tokenizer(\n",
    "            f\"User: {prompt}\\n\\n질문: {x}\\n\\nAssistant:\",      # 사용자 프롬프트에 직접 질문과 입력값(x) 결합\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda')                                          # 텐서를 GPU로 전달\n",
    "\n",
    "    gened = model.generate(\n",
    "        **rt,                                                 # 입력 텐서(문장 변환)\n",
    "        do_sample=True,                                       # 샘플링(확률적 생성) 활성화\n",
    "        generation_config=gen_cfg,                            # 위에서 정의한 생성 파라미터 적용\n",
    "        streamer=streamer,                                    # 실시간 토큰 스트리밍 활성\n",
    "    )\n",
    "\n",
    "    result = tokenizer.decode(gened[0])                       # 숫자 시퀀스를 한글 텍스트로 변환\n",
    "    answer = result.split('Assistant:')                       # AI 답변 기준으로 문장 분리\n",
    "\n",
    "    # return answer[1].strip()                                # 필요시 'Assistant:' 이후 실제 답변만 반환\n",
    "    return result                                             # 전체 생성 결과 반환\n",
    "\n",
    "query = \"\"\"50세 남성이 최근 치과 검진에서 잇몸 출혈과 치아 사이의 플라그 축적으로 진단받았습니다. 치주 질환과 충치를 예방하기 위해 가장 우선적으로 권장되는 구강 관리 방법은 무엇입니까?  \n",
    "1) 하루에 두 번 칫솔질하기  \n",
    "2) 정기적인 스케일링 받기  \n",
    "3) 구강 세정제 사용하기  \n",
    "4) 치실 사용하기  \n",
    "5) 치간 칫솔 사용하기\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a9c011b-5370-424a-8ac3-1c4b4cbf35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>User: 질문에 해당되는 답변의 번호를 알려주세요\n",
      "\n",
      "\n",
      "질문: 50세 남성이 최근 치과 검진에서 잇몸 출혈과 치아 사이의 플라그 축적으로 진단받았습니다. 치주 질환과 충치를 예방하기 위해 가장 우선적으로 권장되는 구강 관리 방법은 무엇입니까?  \n",
      "1) 하루에 두 번 칫솔질하기  \n",
      "2) 정기적인 스케일링 받기  \n",
      "3) 구강 세정제 사용하기  \n",
      "4) 치실 사용하기  \n",
      "5) 치간 칫솔 사용하기\n",
      "\n",
      "Assistant: 2) 정기적인 스케일링 받기<|endoftext|>정기적인 스케일링은 치주 질환과 충치를 예방하는 데 가장 효과적인 방법입니다. 스케일링은 치아 사이의 플라그를 제거하여 치주 질환의 발생을 줄이고, 치아의 건강을 유지하는 데 도움을 줍니다. 따라서 정기적인 스케일링은 치과 방문 시 가장 중요한 관리 방법 중 하나입니다. \n",
      "                    Assistant: 2) 정기적인 스케일링 받기<|endoftext\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>User: 질문에 해당되는 답변의 번호를 알려주세요\\n\\n\\n질문: 50세 남성이 최근 치과 검진에서 잇몸 출혈과 치아 사이의 플라그 축적으로 진단받았습니다. 치주 질환과 충치를 예방하기 위해 가장 우선적으로 권장되는 구강 관리 방법은 무엇입니까?\\xa0\\xa0\\n1) 하루에 두 번 칫솔질하기\\xa0\\xa0\\n2) 정기적인 스케일링 받기\\xa0\\xa0\\n3) 구강 세정제 사용하기\\xa0\\xa0\\n4) 치실 사용하기\\xa0\\xa0\\n5) 치간 칫솔 사용하기\\n\\nAssistant: 2) 정기적인 스케일링 받기<|endoftext|>정기적인 스케일링은 치주 질환과 충치를 예방하는 데 가장 효과적인 방법입니다. 스케일링은 치아 사이의 플라그를 제거하여 치주 질환의 발생을 줄이고, 치아의 건강을 유지하는 데 도움을 줍니다. 따라서 정기적인 스케일링은 치과 방문 시 가장 중요한 관리 방법 중 하나입니다. \\n                    Assistant: 2) 정기적인 스케일링 받기<|endoftext'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cb867-1abc-446b-a712-b5c77bf50e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
