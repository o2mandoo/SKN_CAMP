{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77a62fa-99d4-4f59-85f5-f16659e5c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "# transformers \n",
    "# datasets \n",
    "# evaluate \n",
    "# trl \n",
    "# huggingface_hub \n",
    "# accelerate \n",
    "# wandb \n",
    "# scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e89f3af-fb8c-426f-a217-ae499a8fd2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdaf89f671d4beea8c8774a9582b0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    pipeline, \n",
    "    Trainer\n",
    ")\n",
    "from transformers.integrations import WandbCallback\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "import evaluate\n",
    "\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9aabe08-a423-49ff-8a61-b753c4a9f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_dataset(\"jaehy12/news3\")\n",
    "\n",
    "element = dataset['train'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774b109b-2115-4bbd-bf6e-eddca9d5fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #한국어 요약만 시켰을 때\n",
    "\n",
    "def get_chat_format(example):\n",
    "    return [\n",
    "            {\"role\": \"user\", \"content\": f\"다음 텍스트를 한국어로 간단히 요약 및 관련 키워를 추출해주세요:\\n{example['original']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"한국어 요약:\\n{example['summary']}\"}\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7709ae66-f649-4ebb-8229-4256ea5b9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = tokenizer.apply_chat_template(\n",
    "    get_chat_format(element), tokenize=False\n",
    ")\n",
    "\n",
    "\n",
    "input_text = \"\"\"다음 텍스트를 한국어로 간단히 요약해주세요:\\n부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
    "유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
    "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\n",
    "A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
    "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\n",
    "반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\n",
    "사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\n",
    "사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\n",
    "경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\"\"\"\n",
    "\n",
    "def change_inference_chat_format(input_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"{input_text}\"},\n",
    "\t{\"role\": \"assistant\", \"content\": \"\"\"부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
    "     유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"중요한 키워드 5개를 뽑아주세요.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c15aeea5-48ea-4dd8-9d84-087933e56d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "다음 텍스트를 한국어로 간단히 요약해주세요:\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\n",
      "A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
      "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\n",
      "반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\n",
      "사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\n",
      "사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\n",
      "경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\n",
      "model\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "     유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "user\n",
      "중요한 키워드 5개를 뽑아주세요.\n",
      "model\n",
      "\n",
      "model\n",
      "- 부산의 한 왕복 2차선 도로에서 역주행 사고\n",
      "- 배달 오토바이 운전자\n",
      "- 고등학생\n",
      "- 유족\n",
      "- 늑장 대응\n"
     ]
    }
   ],
   "source": [
    "prompt = change_inference_chat_format(input_text)\n",
    "\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    prompt, \n",
    "    tokenize=True, \n",
    "    add_generation_prompt=True, \n",
    "    return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.to(model.device), \n",
    "    max_new_tokens=256\n",
    "    )\n",
    "print(tokenizer.decode(\n",
    "    outputs[0], \n",
    "    skip_special_tokens=True\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c454ff-5954-410b-b95b-8c5539bd3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_inference_chat_format(input_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"{input_text}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"한국어 요약:\\n\"}\n",
    "    ]\n",
    "prompt = change_inference_chat_format(input_text)\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(prompt,\n",
    "                                       tokenize=True, \n",
    "                                       add_generation_prompt=True,\n",
    "                                       return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(inputs, max_new_tokens=256, use_cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4337c4-88d2-421e-8b19-6768fc152651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "다음 텍스트를 한국어로 간단히 요약해주세요:\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다.\n",
      "유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다.\n",
      "11일 부산진경찰서는 교통사고처리특례법(교통사고처리법)상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다고 밝혔다.\n",
      "A씨는 교통사고처리법상 12대 중과실에 해당되는 '중앙선 침범'으로 역주행 교통사고를 일으킨 혐의를 받는다.\n",
      "경찰에 따르면 스포츠유틸리티차량(SUV) 운전자 A씨는 5월 19일 밤 11시 50분쯤 부산진구 가야고가교 밑 도로에서 중앙선을 넘어 역주행으로 140m를 달려\n",
      "반대편 차선의 오토바이 운전자 조모(16)군을 들이받았다. 조군은 원동기장치자전거 면허를 취득한 상태였고 헬멧도 쓰고 있었지만 크게 다쳤다.\n",
      "사고 당일 수술을 받았으나 얼마 후 2차 뇌출혈로 뇌사 판정이 내려졌고, 사고 발생 약 한 달 만인 지난달 16일 끝내 사망했다.\n",
      "사고를 낸 A씨는 술을 마시거나 약물을 복용한 상태에서 운전하지는 않은 것으로 조사됐다.\n",
      "경찰 관계자는 'A씨가 자신이 정주행을 하고 오토바이가 역주행을 한 것으로 착각했다고 진술했다'고 설명했다.\n",
      "model\n",
      "한국어 요약:\n",
      "model\n",
      "부산의 한 왕복 2차선 도로에서 역주행 사고로 배달 오토바이 운전자인 고등학생이 숨지는 사고가 발생했다. 유족은 '가해자가 사고 후 곧바로 신고하지 않고 늑장 대응해 피해를 키웠다'고 주장하고 있다. 경찰은 교통사고처리법상 업무상 과실치사 혐의로 지난 3일 A(59)씨를 검찰에 불구속 송치했다.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe44762-b489-492f-9d4d-5b7641085742",
   "metadata": {},
   "source": [
    "# 키워드 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802840ed-29c7-4c08-b228-f11b7ceb0b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
    "\n",
    "\n",
    "def key_word_prompt(input_text, summary_text):\n",
    "    return [\n",
    "    {\"role\": \"user\", \"content\": f\"{input_text}\"},\n",
    "    {\"role\": \"assistant\", \"content\": f\"{summary_text}\"},\n",
    "    {\"role\": \"user\", \"content\": \"중요한 키워드 5개를 뽑아주세요.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ]\n",
    "\n",
    "def extract_keywords_batch(batch):\n",
    "    prompts = [key_word_prompt(original, summary) for original, summary in zip(batch[\"original\"], batch[\"summary\"])]\n",
    "\n",
    "    generated_texts = pipe(prompts, max_new_tokens=150, return_full_text=False)\n",
    "    keywords = [gen_text[0][\"generated_text\"] for gen_text in generated_texts]\n",
    "    batch[\"keywords\"] = keywords\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d254205-c85b-4504-8e9c-d61907c5fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21e7ac07-a263-4b0d-9e90-64d82e046311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd24e4d9bd644d9828bf88474b7a791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = sample_dataset.map(extract_keywords_batch, batched=True, batch_size=20)  # 적절한 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce11e13f-01e3-4ef3-be1d-58da470ff428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2576fa45d048410eaeca58f9db7216d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chat_keyword_summary_format(example):\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": f\"다음 텍스트를 한국어로 간단히 요약 및 관련 키워를 추출해주세요:\\n{example['original']}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"한국어 요약:{example['summary']}\\n키워드:{example['keywords']}\"}\n",
    "    ]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    chat_keyword_summary_format(sample_dataset[0]), tokenize=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def tokenize(element):\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        chat_keyword_summary_format(element), tokenize=False\n",
    "    ) + EOS_TOKEN\n",
    "    outputs = tokenizer(formatted)\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tokenized_sample_dataset = sample_dataset.map(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c72f51-39d5-43c1-a65d-91320e766ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sample_dataset = tokenized_sample_dataset.train_test_split(\n",
    "    test_size=0.1, \n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5d06a38-5984-43d3-95c3-0faf6ebf2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template_ids = tokenizer.encode(\n",
    "    \"<start_of_turn>model\\n\", \n",
    "    add_special_tokens=False\n",
    "    )\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template_ids, tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91730334-b6aa-4d4f-a5e9-734b8e028501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.init(project=\"gemma-2B-it-Full-Fine-Tuning\", entity=\"c08c4325e74501f73b8118bf55c5f2dd64654576\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./keywords_gemma_results\",\n",
    "    # num_train_epochs=1, # 1epoch에 250step정도 진행함 \n",
    "    max_steps=800,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"wandb\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aad9570-8012-459e-9b20-be9c95ee863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "acc = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82f430b3-5cbb-49d2-9877-b814d7033059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1872/3751762327.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "You are adding a <class 'transformers.integrations.integration_utils.WandbCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "WandbCallback\n"
     ]
    }
   ],
   "source": [
    "# Trainer에서 BLEU 및 정확도(accuracy) 커스텀 평가 함수와 logits 후처리(preprocess) 적용 예제\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    # 헤드라이너: 모델 outputs(logits)에서 실제 예측 토큰(토큰ID) 추출(평가지표 계산 전용)\n",
    "    if isinstance(logits, tuple):\n",
    "        # 일부 모델은 logits 외에 추가 정보(past_key_values 등)를 반환하므로 첫 요소만 사용\n",
    "        logits = logits[0]\n",
    "    # 각 위치별 가장 확률 높은 토큰ID(argmax) 반환 → 평가용 예측값\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    # 헤드라이너: 평가 데이터에 대해 BLEU·정확도 자동 계산, -100 패딩/마스킹 처리까지 포함\n",
    "    preds, labels = eval_preds   # preds/labels: 각각 예측·정답 토큰ID 시퀀스(batch, seq_len)\n",
    "    # preds와 labels는 동일 시퀀스 길이(모델의 평가용 argmax 결과)\n",
    "    # ChatCompletion, auto-regressive LM 등엔 1-step shift가 필요함\n",
    "    labels = labels[:, 1:]   # 정답(참조) 시퀀스를 한 칸 오른쪽으로 이동(첫 토큰은 ignore)\n",
    "    preds = preds[:, :-1]    # 예측값 역시 마지막 토큰을 제거(길이 맞춤)\n",
    "\n",
    "    # -100은 HF DataCollatorForCompletionOnlyLM 등이 loss 계산 제외용으로 덮는 패딩값임\n",
    "    mask = labels == -100        # -100 위치는 평가에서 무시해야 하는 곳\n",
    "\n",
    "    # -100을 pad_token_id(토크나이저가 이해하는 값)로 임시 치환(디코딩·평가에 활용)\n",
    "    labels[mask] = tokenizer.pad_token_id\n",
    "    preds[mask] = tokenizer.pad_token_id\n",
    "\n",
    "    # BLEU 점수(Corpus Level, n-gram 정합성) 계산용: 텍스트(문장)로 복원\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    bleu_score = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # 정확도(accuracy)는 int list 입력, -100 마스킹 영역 제외(~mask) 후 평가\n",
    "    accuracy = acc.compute(predictions=preds[~mask], references=labels[~mask])\n",
    "\n",
    "    return {**bleu_score, **accuracy}   # 두 지표 모두 딕셔너리로 병합 반환\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,                         # 학습 파라미터(학습률, step 등)\n",
    "    model=model,                                # 학습 및 추론 대상 LLM\n",
    "    tokenizer=tokenizer,                        # 토크나이저(문자열<->토큰 변환)\n",
    "    data_collator=collator,                     # batch/정답 추출용 데이터 collator\n",
    "    train_dataset=tokenized_sample_dataset[\"train\"],   # 학습 데이터셋\n",
    "    eval_dataset=tokenized_sample_dataset[\"test\"],     # 평가(검증) 데이터셋\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,  # logits → 예측 변환\n",
    "    compute_metrics=compute_metrics,            # BLEU/정확도 커스텀 평가 함수\n",
    "    callbacks=[WandbCallback()]\n",
    "    # ... (필요시 callbacks, wandb 등 추가 설정)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7f2d402-0d34-443d-8b57-ce07584d4fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [501/800 02:31 < 01:30, 3.30 it/s, Epoch 0.56/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.844400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:664] . unexpected pos 5284890048 vs 5284889944",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py:967\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    966\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py:1268\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1267\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1268\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/164: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2664\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2662\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2663\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2666\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2669\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2673\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2675\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3144\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3141\u001b[39m         \u001b[38;5;28mself\u001b[39m.control.should_save = is_new_best_metric\n\u001b[32m   3143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3144\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3145\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_save(\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3252\u001b[39m, in \u001b[36mTrainer._save_checkpoint\u001b[39m\u001b[34m(self, model, trial)\u001b[39m\n\u001b[32m   3248\u001b[39m         \u001b[38;5;28mself\u001b[39m.state.best_model_checkpoint = best_checkpoint_dir\n\u001b[32m   3250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_only_model:\n\u001b[32m   3251\u001b[39m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3252\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3253\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_scaler(output_dir)\n\u001b[32m   3254\u001b[39m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3379\u001b[39m, in \u001b[36mTrainer._save_optimizer_and_scheduler\u001b[39m\u001b[34m(self, output_dir)\u001b[39m\n\u001b[32m   3374\u001b[39m     save_fsdp_optimizer(\n\u001b[32m   3375\u001b[39m         \u001b[38;5;28mself\u001b[39m.accelerator.state.fsdp_plugin, \u001b[38;5;28mself\u001b[39m.accelerator, \u001b[38;5;28mself\u001b[39m.optimizer, \u001b[38;5;28mself\u001b[39m.model, output_dir\n\u001b[32m   3376\u001b[39m     )\n\u001b[32m   3377\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.should_save:\n\u001b[32m   3378\u001b[39m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3379\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3381\u001b[39m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[32m   3382\u001b[39m is_deepspeed_custom_scheduler = \u001b[38;5;28mself\u001b[39m.is_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3383\u001b[39m     \u001b[38;5;28mself\u001b[39m.lr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[32m   3384\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py:966\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    963\u001b[39m     f = os.fspath(f)\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py:798\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__exit__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    800\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_stream.close()\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:664] . unexpected pos 5284890048 vs 5284889944"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28064d-30fd-41ea-8bc0-8c19e27a3e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b37bee-10bf-4615-90fa-6b5b2b0ac838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
